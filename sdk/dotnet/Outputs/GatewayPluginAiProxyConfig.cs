// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

using System;
using System.Collections.Generic;
using System.Collections.Immutable;
using System.Threading.Tasks;
using Pulumi.Serialization;

namespace Pulumi.Konnect.Outputs
{

    [OutputType]
    public sealed class GatewayPluginAiProxyConfig
    {
        public readonly Outputs.GatewayPluginAiProxyConfigAuth? Auth;
        public readonly Outputs.GatewayPluginAiProxyConfigLogging? Logging;
        public readonly Outputs.GatewayPluginAiProxyConfigModel? Model;
        /// <summary>
        /// Whether to 'optionally allow', 'deny', or 'always' (force) the streaming of answers via server sent events. must be one of ["allow", "deny", "always"]
        /// </summary>
        public readonly string? ResponseStreaming;
        /// <summary>
        /// The model's operation implementation, for this provider. Set to `preserve` to pass through without transformation. must be one of ["llm/v1/chat", "llm/v1/completions", "preserve"]
        /// </summary>
        public readonly string? RouteType;

        [OutputConstructor]
        private GatewayPluginAiProxyConfig(
            Outputs.GatewayPluginAiProxyConfigAuth? auth,

            Outputs.GatewayPluginAiProxyConfigLogging? logging,

            Outputs.GatewayPluginAiProxyConfigModel? model,

            string? responseStreaming,

            string? routeType)
        {
            Auth = auth;
            Logging = logging;
            Model = model;
            ResponseStreaming = responseStreaming;
            RouteType = routeType;
        }
    }
}
